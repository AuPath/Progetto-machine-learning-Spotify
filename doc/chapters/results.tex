\chapter{Campagna sperimentale}
Nota bene viene usat lo stesso seed per il training, in questo si generarno gli sessi folds
s
\section{Approccio}
\subsection{10-folds cross validation}

\subsection{Training set e test set}

\subsection{Model selection}
\subsubsection{Ottimizzazione iperparametri}
\subsubsection{Grid search}

\section{Misure di performance}
\subsection{Accuracy}
\subsection{Precision, Recall e F-measure}
\subsection{Curve ROC}

\section{Support Vector Machine}
\subsection{Kernel}

\section{Decision Tree} \subsection{Scelta del modello} Come secondo
modello parte del progetto é stato scelto un albero di decisione
(decision tree/classification tree). Questo perché anche con un
dataset relativamente ampio permette il training in un tempo
ragionevole rispetto alla potenza computazionale in nostro possesso.

\section{Esperimenti}
\subsection{Performance}
\section{Modelli a confronto}
