{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "START_PAGE = 'wiki/Categoria:Singoli_certificati_disco_d%27oro_in_Italia'\n",
    "BASE_URL = 'https://it.wikipedia.org/'\n",
    "\n",
    "def scrape_page(page):\n",
    "    with urlopen(page) as request:\n",
    "        body = BeautifulSoup(request.read().decode('utf-8'), 'html.parser')\n",
    "        songs = get_songs_urls(body)\n",
    "        next_page = get_next_page(body)\n",
    "    return songs, next_page\n",
    "\n",
    "def get_songs_urls(body):\n",
    "    songs_div = body.select_one('.mw-category')\n",
    "    return [song.find('a', href=True)['href'] for song in songs_div.find_all('li')]\n",
    "\n",
    "def get_next_page(body):\n",
    "    try:\n",
    "        return body.select_one('.mw-category-generated').find('a', string='pagina successiva')['href']\n",
    "    except TypeError:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def scrape_song_urls():\n",
    "    next_page = START_PAGE\n",
    "    songs_url = []\n",
    "    while next_page:\n",
    "        new_songs, next_page = scrape_page(BASE_URL + next_page)\n",
    "        songs_url += new_songs\n",
    "        print('Scraping links . . .')\n",
    "    print('Links scraped')\n",
    "    return songs_url"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraping links . . .\n",
      "Scraping links . . .\n",
      "Scraping links . . .\n",
      "Scraping links . . .\n",
      "Scraping links . . .\n",
      "Scraping links . . .\n",
      "Scraping links . . .\n",
      "Links scraped\n",
      "Num of songs: 1261\n"
     ]
    }
   ],
   "source": [
    "songs_urls = scrape_song_urls()\n",
    "print('Num of songs: {}'.format(len(songs_urls)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def scrape_song(url):\n",
    "    with urlopen(url) as request:\n",
    "        body = BeautifulSoup(request.read().decode('utf-8'), 'html.parser')\n",
    "    return parse_song(body)\n",
    "\n",
    "\n",
    "def parse_song(body):\n",
    "    song, data_dict = dict(), dict()\n",
    "    table_body = body.find('table', {\"class\": \"sinottico\"}).find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        row_key = row.find('th', text=True)\n",
    "        if row_key:\n",
    "            value = row.find_all('td')\n",
    "            if value:\n",
    "                text = value[0].text\n",
    "                data_dict[row_key.text] = text.strip()\n",
    "    try:\n",
    "        song['title'] = table_body.find('tr', {\"class\": \"sinottico_testata\"}).text.strip()\n",
    "    except:\n",
    "        song['title'] = None\n",
    "    \n",
    "    try:\n",
    "        song['artists'] = ','.join([x.strip() for x in  data_dict['Artista'].split(',')])\n",
    "    except:\n",
    "        song['artists'] = None\n",
    "    \n",
    "    try:\n",
    "        song['date'] = data_dict['Pubblicazione']\n",
    "    except:\n",
    "        try:\n",
    "            song['date'] = data_dict['Data']\n",
    "        except:\n",
    "            song['date'] = None\n",
    "    \n",
    "    try:\n",
    "        song['duration'] = data_dict['Durata']\n",
    "    except:\n",
    "        song['duration'] = None\n",
    "\n",
    "    try:\n",
    "        song['genre'] = data_dict['Genere']\n",
    "    except:\n",
    "        song['genre'] = None\n",
    "    \n",
    "    return song\n",
    "\n",
    "def scrape_songs_info(songs_urls):\n",
    "    songs = []\n",
    "    header = [x for x in scrape_song(BASE_URL + next(iter(songs_urls))).keys()]\n",
    "    df = pd.DataFrame(data=[], columns=header)\n",
    "    for i, url in enumerate(songs_urls):\n",
    "        percentage = round(i/len(songs_urls) * 100, 3)\n",
    "        print('\\rDownloading: {}/{} - {}%'.format(i + 1, len(songs_urls), percentage), end = '')\n",
    "        if i == 10:\n",
    "            break\n",
    "        new_song = scrape_song(BASE_URL + url)\n",
    "        df = df.append(new_song, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading: 11/1261 - 0.793%"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          title      artists              date  \\\n",
       "0                       0ffline  Tha Supreme    31 luglio 2020   \n",
       "1                       1, 2, 3  Sofía Reyes  16 febbraio 2018   \n",
       "2                       3 Words       Cheryl  18 dicembre 2009   \n",
       "3  4/3/1943/Il fiume e la città  Lucio Dalla              1971   \n",
       "4                          5olo  Tha Supreme   9 febbraio 2018   \n",
       "\n",
       "                                    duration                genre  \n",
       "0                                       3:21                 Trap  \n",
       "1                                       3:21  Pop latinoReggaeton  \n",
       "2                                       4:33            Dance pop  \n",
       "3  3:40 (4/3/1943)3:48 (Il fiume e la città)      Musica d'autore  \n",
       "4                                       2:07              Hip hop  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>artists</th>\n      <th>date</th>\n      <th>duration</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0ffline</td>\n      <td>Tha Supreme</td>\n      <td>31 luglio 2020</td>\n      <td>3:21</td>\n      <td>Trap</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1, 2, 3</td>\n      <td>Sofía Reyes</td>\n      <td>16 febbraio 2018</td>\n      <td>3:21</td>\n      <td>Pop latinoReggaeton</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3 Words</td>\n      <td>Cheryl</td>\n      <td>18 dicembre 2009</td>\n      <td>4:33</td>\n      <td>Dance pop</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4/3/1943/Il fiume e la città</td>\n      <td>Lucio Dalla</td>\n      <td>1971</td>\n      <td>3:40 (4/3/1943)3:48 (Il fiume e la città)</td>\n      <td>Musica d'autore</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5olo</td>\n      <td>Tha Supreme</td>\n      <td>9 febbraio 2018</td>\n      <td>2:07</td>\n      <td>Hip hop</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 322
    }
   ],
   "source": [
    "df = scrape_songs_info(songs_urls)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "df.to_csv('../data/disco-oro.csv', index=False, quoting=csv.QUOTE_ALL, quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}